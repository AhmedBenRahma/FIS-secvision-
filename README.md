# üìà Fis SECVision ‚Äî Customer Movement Analytics





[![Python Version](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/) [![Streamlit](https://img.shields.io/badge/Streamlit-1.30%2B-red.svg)](https://streamlit.io) [![YOLOv8](https://img.shields.io/badge/YOLOv8-ultralytics-blueviolet.svg)](https://ultralytics.com/)

Plateforme d'analyse vid√©o par IA con√ßue pour fournir aux exploitants de points de vente des m√©triques sur le comportement et la circulation des clients : comptage, temps de pr√©sence (dwell time), suivi multi-personnes et exports analytiques.

---


## Aper√ßu
Fis Vision analyse des vid√©os (ou flux) pour d√©tecter et suivre des personnes, mesurer les entr√©es/sorties d'une Zone d'Int√©r√™t (ROI) d√©finie et calculer des m√©triques exploitables (ex : fr√©quentation horaire, temps moyen pass√© sur un rayon). L'interface Streamlit permet de d√©finir la ROI, uploader une vid√©o et visualiser la vid√©o annot√©e, le journal d'√©v√©nements et des graphiques d'affluence.
<img width="1713" height="909" alt="582440185_820038594075683_782456656528039243_n" src="https://github.com/user-attachments/assets/b4b22990-ef2c-4604-b95c-de04d8326268" />
<img width="1667" height="835" alt="581747989_908513228167064_2117190142543821954_n" src="https://github.com/user-attachments/assets/c368863d-a105-42d4-a1b5-30299158ec7d" />

Les captures ci‚Äëdessus montrent :
- l'interface utilisateur (d√©finition de la GREEN ZONE, upload),
- la vid√©o annot√©e avec bounding boxes et trajectoires,
- un graphique d'affluence temporelle.

---

## Fonctionnalit√©s cl√©s
- D√©tection et suivi multi-personnes (YOLOv8 + tracker).
- Zone d'Int√©r√™t (ROI) dynamique et personnalisable.
- Enregistrement d'√©v√©nements : ZONE_ENTER, ZONE_EXIT (horodatage, person_id, dur√©e).
- Calcul du dwell time par visiteur et agr√©gation de statistiques.
- Tableau de bord Streamlit : vid√©o annot√©e, journal, graphiques.
- Exports : events.csv, persons.json, vid√©o annot√©e (optionnel).
- Module d'alerte (d√©tection de comportements anormaux) ‚Äî optionnel.

---

## Pr√©requis
- Python 3.8+
- Git
- Optional GPU: CUDA 11.x / 12.x (pour acc√©l√©rer inference avec torch)
- Espace disque pour outputs (vid√©os annot√©es, logs)

---

## Installation rapide

1. Cloner le d√©p√¥t
```bash
git clone [VOTRE_URL]/FIS-secvision.git
cd FIS-secvision
```

2. Cr√©er et activer un environnement virtuel
- Windows
```bash
python -m venv venv
venv\Scripts\activate
```
- macOS / Linux
```bash
python -m venv venv
source venv/bin/activate
```

3. Installer les d√©pendances
```bash
pip install -r requirements.txt
```
Remarque : si vous utilisez GPU, installez torch compatible CUDA avant d'installer les autres paquets (voir docs PyTorch).

4. Lancer l'application Streamlit
```bash
streamlit run app.py
```
Par d√©faut l'UI est disponible sur http://localhost:8501

---

## Utilisation (pas √† pas)
1. Ouvrir l'UI Streamlit.
2. D√©finir la GREEN ZONE (ROI) : entrer les coordonn√©es (format expliqu√© plus bas) ou utiliser l'outil de dessin si pr√©sent.
3. Uploader une vid√©o MP4 (ou s√©lectionner un flux cam√©ra si impl√©ment√©).
4. Cliquer sur "RUN DETECTION".
5. Visualiser :
   - la vid√©o annot√©e (bounding boxes, IDs, trajectoires),
   - le journal d'√©v√©nements (events.csv),
   - les graphiques d'affluence / dwell time.
6. T√©l√©charger les exports pour analyses externes.

---

## Format de la GREEN ZONE (ROI)
Le champ attend une liste de points qui dessinent un polygone. Accepted formats (exemples) :
- Paire s√©par√©e par espace : "x1,y1 x2,y2 x3,y3 x4,y4"
- Exemple utilis√© dans l'UI :  
  850,350 10,550 10,1400 2700,1400 2700,700

Conseils :
- Les coordonn√©es sont en pixels par rapport √† la r√©solution de la vid√©o.
- V√©rifiez l'ordre des points (sens horaire/anti-horaire) si la d√©tection d'entr√©e/sortie semble invers√©e.

---

## Sorties g√©n√©r√©es
Par d√©faut les r√©sultats sont stock√©s dans le dossier `outputs/` (configurable).

- outputs/events.csv  
  Colonnes typiques : timestamp, person_id, event_type, zone_id, duration_seconds, x, y, frame_number  
  Exemple de ligne :  
  2025-11-17T07:39:15.123Z, 3, ZONE_ENTER, green_zone, , 850,350, 2245

- outputs/persons.json  
  Structure JSON : statistiques agr√©g√©es par personne (id, total_time_in_zone, num_entries, first_seen, last_seen)

- outputs/annotated_<input_name>.mp4 (si activ√©)  
  Vid√©o d'entr√©e avec bo√Ætes, IDs, trajectoires et annotations de la ROI.

---

## Configuration & variables d'environnement
Variables utiles :
- PORT ‚Äî Port Streamlit (d√©faut 8501)
- MODEL_WEIGHTS ‚Äî Chemin vers les poids YOLOv8 (ex: weights/yolov8n.pt)
- OUTPUT_DIR ‚Äî Dossier des sorties (d√©faut : outputs/)
- TRACKER_CONF ‚Äî Param√®tres du tracker (IOU, distance, etc.)

Exemple `.env` :
```env
PORT=8501
MODEL_WEIGHTS=weights/yolov8n.pt
OUTPUT_DIR=outputs
```

---

## Bonnes pratiques & optimisation
- Pour traitement temps r√©el, ex√©cutez sur GPU (CUDA) et utilisez un mod√®le YOLOv8 l√©ger (ex : yolov8n).
- R√©duisez la r√©solution d'entr√©e si la pr√©cision reste suffisante.
- Ajustez les seuils de confiance (confidence) et l'IOU du tracker pour limiter le re‚Äëassignement de IDs.
- Filtrez objets par taille/min area pour √©viter faux positifs (sacs, petites zones).

---


